"""
Audio Upload and Prediction Routes
"""

from fastapi import APIRouter, UploadFile, File, Depends, HTTPException, status, Query
from typing import Optional
import os
from datetime import datetime
from pathlib import Path
import logging
import librosa
import time

from app.models import User, Tractor, AudioPrediction
from app.core.security import get_current_user
from app.services.ml_service import MLService
from app.schemas import AudioPredictionResponse

router = APIRouter()
logger = logging.getLogger(__name__)

# Initialize ML service
ml_service = MLService()

# Create uploads directory
UPLOAD_DIR = Path("uploads/audio")
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)


@router.post("/upload", response_model=AudioPredictionResponse)
async def upload_audio(
    tractor_id: str = Query(..., description="Tractor ID"),
    file: UploadFile = File(..., description="Audio file (.wav, .mp3, etc.)"),
    current_user: User = Depends(get_current_user)
):
    """Upload audio file and get tractor health prediction using 98.9% accurate SVM model"""
    
    start_time = time.time()
    
    try:
        # Verify tractor
        tractor = await Tractor.find_one({
            "tractor_id": tractor_id.upper(),
            "owner_id": str(current_user.id)
        })
        
        if not tractor:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Tractor {tractor_id} not found"
            )
        
        # Save file
        timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
        file_extension = os.path.splitext(file.filename)[1]
        filename = f"{tractor_id}_{timestamp}{file_extension}"
        file_path = UPLOAD_DIR / filename
        
        logger.info(f"Saving audio file: {filename}")
        content = await file.read()
        with open(file_path, "wb") as f:
            f.write(content)
        
        # Get file info
        file_size = len(content)
        
        # Get audio metadata
        try:
            y, sr = librosa.load(str(file_path), duration=None)
            duration = float(len(y) / sr)
            sample_rate = int(sr)
        except Exception as e:
            logger.warning(f"Could not read audio metadata: {e}")
            duration = 5.0
            sample_rate = 22050
        
        # Make prediction
        logger.info(f"Running prediction for tractor: {tractor_id}")
        prediction_start = time.time()
        
        prediction_result = await ml_service.predict_audio(
            audio_path=str(file_path),
            tractor_id=tractor_id.upper()
        )
        
        processing_time = (time.time() - prediction_start) * 1000  # Convert to ms
        
        # Map prediction to lowercase (matches PredictionClass enum)
        prediction_class = prediction_result["prediction_class"].lower()
        confidence = prediction_result["confidence"]
        anomaly_score = prediction_result.get("anomaly_score", 0.0)
        
        # Create prediction with exact schema fields
        audio_prediction = AudioPrediction(
            tractor_id=tractor_id.upper(),
            # File info
            filename=filename,
            file_path=str(file_path),
            file_size_bytes=file_size,
            duration_seconds=duration,
            # Prediction
            prediction_class=prediction_class,  # "normal" or "abnormal"
            confidence=confidence,
            model_used="SVM",
            # Analysis metadata
            processing_time_ms=processing_time,
            sample_rate=sample_rate,
            # Timestamps (auto-generated by default_factory)
            recorded_at=datetime.utcnow(),
            processed_at=datetime.utcnow()
        )
        
        await audio_prediction.insert()
        logger.info(f"✅ Prediction saved: {prediction_class} (confidence: {confidence:.2%})")
        
        # Calculate total processing time
        total_time = (time.time() - start_time) * 1000
        
        # Return response
        return AudioPredictionResponse(
            id=str(audio_prediction.id),
            tractor_id=audio_prediction.tractor_id,
            prediction_class=audio_prediction.prediction_class,
            confidence=audio_prediction.confidence,
            anomaly_score=anomaly_score,
            audio_file_path=audio_prediction.file_path,
            recorded_at=audio_prediction.recorded_at,
            filename=audio_prediction.filename,
            model_used=audio_prediction.model_used,
            duration_seconds=audio_prediction.duration_seconds
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"❌ Error processing audio: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error processing audio: {str(e)}"
        )

@router.get("/predictions/{tractor_id}")
async def get_predictions(
    tractor_id: str,
    limit: int = Query(50, ge=1, le=100),
    current_user: User = Depends(get_current_user)
):
    """Get audio prediction history for a tractor"""
    
    # Verify tractor
    tractor = await Tractor.find_one({
        "tractor_id": tractor_id.upper(),
        "owner_id": str(current_user.id)
    })
    
    if not tractor:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Tractor {tractor_id} not found"
        )
    
    # Get predictions
    predictions = await AudioPrediction.find(
        {"tractor_id": tractor_id.upper()}
    ).sort("-recorded_at").limit(limit).to_list()
    
    # Return with safe field access
    return [
        AudioPredictionResponse(
            id=str(p.id),
            tractor_id=p.tractor_id,
            prediction_class=p.prediction_class,
            confidence=p.confidence,
            anomaly_score=(1.0 - p.confidence) if p.prediction_class == "normal" else p.confidence,
            audio_file_path=p.file_path,
            recorded_at=p.recorded_at,
            # Safely access fields that may not exist in old records
            filename=getattr(p, 'filename', 'unknown'),
            model_used=getattr(p, 'model_used', 'SVM'),
            duration_seconds=getattr(p, 'duration_seconds', 5.0)
        )
        for p in predictions
    ]

@router.get("/model/info")
async def get_model_info(current_user: User = Depends(get_current_user)):
    """Get information about the loaded ML model"""
    
    model_info = ml_service.get_model_info()
    
    return {
        "model_name": "SVM Classifier (Support Vector Machine)",
        "accuracy": "98.9%",
        "precision": "98.9%",
        "recall": "98.9%",
        "f1_score": "98.9%",
        "roc_auc": "99.9%",
        "classes": ["normal", "abnormal"],
        "features": {
            "type": "Statistical features from MFCCs",
            "n_mfcc": 40,
            "statistics": [
                "mean", "std", "max", "min", "median",
                "delta_mean", "delta_std",
                "delta2_mean", "delta2_std"
            ],
            "total_features": 360
        },
        "preprocessing": {
            "sample_rate": 22050,
            "duration": 5.0,
            "highpass_filter": True,
            "cutoff_frequency": "100 Hz"
        },
        "source": "Google Drive",
        "loaded_from_cache": model_info.get("model_loaded", False),
        **model_info
    }


@router.get("/statistics/{tractor_id}")
async def get_prediction_statistics(
    tractor_id: str,
    current_user: User = Depends(get_current_user)
):
    """Get prediction statistics for a tractor"""
    
    # Verify tractor
    tractor = await Tractor.find_one({
        "tractor_id": tractor_id.upper(),
        "owner_id": str(current_user.id)
    })
    
    if not tractor:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Tractor {tractor_id} not found"
        )
    
    # Get all predictions
    predictions = await AudioPrediction.find(
        {"tractor_id": tractor_id.upper()}
    ).to_list()
    
    if not predictions:
        return {
            "tractor_id": tractor_id.upper(),
            "total_predictions": 0,
            "normal_count": 0,
            "abnormal_count": 0,
            "average_confidence": 0.0
        }
    
    # Calculate statistics
    total = len(predictions)
    normal_count = sum(1 for p in predictions if p.prediction_class == "normal")
    abnormal_count = total - normal_count
    avg_confidence = sum(p.confidence for p in predictions) / total
    
    # Get recent trend (last 10 predictions)
    recent = predictions[-10:] if len(predictions) > 10 else predictions
    recent_abnormal = sum(1 for p in recent if p.prediction_class == "abnormal")
    
    return {
        "tractor_id": tractor_id.upper(),
        "total_predictions": total,
        "normal_count": normal_count,
        "abnormal_count": abnormal_count,
        "normal_percentage": (normal_count / total) * 100,
        "abnormal_percentage": (abnormal_count / total) * 100,
        "average_confidence": avg_confidence,
        "recent_trend": {
            "last_10_predictions": len(recent),
            "abnormal_in_last_10": recent_abnormal,
            "health_status": "Critical" if recent_abnormal >= 7 else "Warning" if recent_abnormal >= 4 else "Good"
        },
        "latest_prediction": {
            "class": predictions[-1].prediction_class,
            "confidence": predictions[-1].confidence,
            "recorded_at": predictions[-1].recorded_at
        } if predictions else None
    }